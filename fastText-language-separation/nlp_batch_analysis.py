import os
import random
import time
from transformers import pipeline
from deep_translator import GoogleTranslator

# --- AYARLAR ---
# ≈ûarkƒ± dosyalarƒ±nƒ±n olduƒüu klas√∂r yolu (Kendi yoluna g√∂re d√ºzenle)
LYRICS_DIR = "../lyrics_files" 
MODEL_NAME = "bhadresh-savani/bert-base-uncased-emotion"

def analyze_local_files():
    # 1. Klas√∂rdeki t√ºm .txt dosyalarƒ±nƒ± bul
    if not os.path.exists(LYRICS_DIR):
        print(f"HATA: '{LYRICS_DIR}' klas√∂r√º bulunamadƒ±!")
        return

    all_files = [f for f in os.listdir(LYRICS_DIR) if f.endswith(".txt")]
    
    if not all_files:
        print("Klas√∂rde hi√ß .txt dosyasƒ± yok!")
        return

    # Rastgele 5 ≈üarkƒ± se√ß (Test ama√ßlƒ±)
    selected_files = random.sample(all_files, min(5, len(all_files)))
    
    print(f"üìÇ Toplam {len(all_files)} dosya bulundu. Rastgele {len(selected_files)} tanesi analiz edilecek.\n")
    
    # 2. Modeli ve √áevirmeni Hazƒ±rla
    print("‚è≥ Model y√ºkleniyor...")
    emotion_classifier = pipeline(
        "text-classification", 
        model=MODEL_NAME, 
        return_all_scores=True,
        truncation=True  # √áok uzun metinleri otomatik kƒ±rpar (Hata almamak i√ßin ≈üart)
    )
    translator = GoogleTranslator(source='tr', target='en')

    print("\nüöÄ DOSYA ANALƒ∞Zƒ∞ BA≈ûLIYOR...\n" + "="*60)

    for filename in selected_files:
        filepath = os.path.join(LYRICS_DIR, filename)
        
        # Dosya isminden ≈üarkƒ± ve sanat√ßƒ±yƒ± ayƒ±kla (G√∂rsellik i√ßin)
        display_name = filename.replace(".txt", "")
        
        try:
            # Dosyayƒ± Oku
            with open(filepath, "r", encoding="utf-8") as f:
                original_lyrics = f.read()
            
            # Bo≈ü dosya kontrol√º
            if not original_lyrics.strip():
                print(f"‚ö†Ô∏è {display_name} -> Dosya bo≈ü, ge√ßiliyor.")
                continue

            # Veri temizliƒüi (√áok uzun satƒ±rlarƒ± birle≈ütir vs.)
            # BERT modeli en fazla 512 token alƒ±r. √áeviri API'sini yormamak i√ßin ilk 1000 karakteri alalƒ±m.
            text_to_process = original_lyrics[:1000] 

            print(f"üéµ {display_name}")
            
            # √áeviri (TR -> EN)
            translated_text = translator.translate(text_to_process)
            
            # √áeviri bazen bo≈ü d√∂nebilir kontrol√º
            if not translated_text:
                print("‚ùå √áeviri ba≈üarƒ±sƒ±z oldu.")
                continue

            # Duygu Analizi
            predictions = emotion_classifier(translated_text)
            
            # Skorlama
            scores = predictions[0]
            scores.sort(key=lambda x: x['score'], reverse=True)
            
            top_emotion = scores[0]
            second_emotion = scores[1]
            
            print(f"   üèÜ {top_emotion['label'].upper()} (%{top_emotion['score']*100:.1f}) | ü•à {second_emotion['label']} (%{second_emotion['score']*100:.1f})")
            print(f"   üåç (√áeviri √ñzeti): \"{translated_text[:60]}...\"")
            print("-" * 60)

        except Exception as e:
            print(f"‚ùå HATA ({display_name}): {e}")
        
        # Google Translate API ban yememek i√ßin bekleme
        time.sleep(1.5)

if __name__ == "__main__":
    analyze_local_files()