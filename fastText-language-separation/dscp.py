import pandas as pd
from sklearn.preprocessing import MinMaxScaler
import re

# --- DOSYA Ä°SÄ°MLERÄ° ---
NLP_DATASET_PATH = "final_music_analysis_dataset.csv"
AUDIO_DATASET_PATH = "songs_with_language.csv" # Veya senin en son temiz audio dosyan
OUTPUT_FILENAME = "FINAL_PROJECT_DATASET.csv"

def clean_track_metadata(text):
    """
    ÅarkÄ± ismindeki gÃ¼rÃ¼ltÃ¼leri (Remix, Live, Parantezler) temizler.
    """
    if pd.isna(text): return ""
    text = str(text).lower()
    
    # 1. Parantez iÃ§lerini sil (...) ve [...]
    text = re.sub(r"\(.*?\)", "", text)
    text = re.sub(r"\[.*?\]", "", text)
    
    # 2. Gereksiz kelimeleri sil
    # Buraya eÅŸleÅŸmeyi bozan kelimeleri ekleyebilirsin
    noise_words = ["remix", "live", "akustik", "acoustic", "version", "feat", "ft.", "edit"]
    for word in noise_words:
        text = text.replace(word, "")
        
    return text

def create_final_dataset():
    print("ğŸ“‚ Dosyalar yÃ¼kleniyor...")
    
    try:
        df_nlp = pd.read_csv(NLP_DATASET_PATH)
        df_audio = pd.read_csv(AUDIO_DATASET_PATH)
    except FileNotFoundError:
        print("âŒ Dosyalar bulunamadÄ±.")
        return

    # --- 1. Audio Verisindeki SanatÃ§Ä±larÄ± Temizle ---
    print("ğŸ§¹ SanatÃ§Ä± ve ÅarkÄ± isimleri temizleniyor...")
    # NoktalÄ± virgÃ¼l (;) varsa bÃ¶l ve ilkini al
    df_audio['primary_artist'] = df_audio['artists'].astype(str).apply(lambda x: x.split(';')[0].split(',')[0].strip())

    # --- 2. Anahtar OluÅŸturma Fonksiyonu (GÃœNCELLENDÄ°) ---
    def make_merge_key(row, source_type):
        """
        Hem NLP hem Audio iÃ§in ortak bir anahtar Ã¼retir.
        """
        if source_type == 'audio':
            track = row['track_name']
            artist = row['primary_artist']
        else: # nlp
            track = row['track name']
            artist = row['artists']
            
        # A. Ã–nce GÃ¼rÃ¼ltÃ¼leri Sil (Live, Remix, Parantez)
        track_clean = clean_track_metadata(track)
        artist_clean = clean_track_metadata(artist) # SanatÃ§Ä±da genelde gerekmez ama garanti olsun
        
        # B. TÃ¼rkÃ§e Karakter ve Sembol TemizliÄŸi
        combined = track_clean + artist_clean
        
        # TÃ¼rkÃ§e karakterleri Ä°ngilizceye Ã§evir
        replacements = str.maketrans("Ã§ÄŸÄ±Ã¶ÅŸÃ¼", "cgiosu")
        combined = combined.translate(replacements)
        
        # AlfanÃ¼merik olmayan her ÅŸeyi sil
        final_key = re.sub(r'[^a-z0-9]', '', combined)
        
        return final_key

    print("ğŸ”— AkÄ±llÄ± Anahtarlar OluÅŸturuluyor...")
    
    # NLP Key
    df_nlp['merge_key'] = df_nlp.apply(lambda row: make_merge_key(row, 'nlp'), axis=1)
    
    # Audio Key
    df_audio['merge_key'] = df_audio.apply(lambda row: make_merge_key(row, 'audio'), axis=1)

    # Audio verisindeki kopyalarÄ± temizle (AynÄ± key'den birden fazla varsa ilki kalsÄ±n)
    df_audio = df_audio.drop_duplicates(subset="merge_key", keep="first")

    # BirleÅŸtirme
    audio_cols = [
        "merge_key", "danceability", "energy", "loudness", 
        "speechiness", "acousticness", "instrumentalness", 
        "liveness", "valence", "tempo"
    ]
    # Sadece var olan sÃ¼tunlarÄ± seÃ§ (Hata almamak iÃ§in)
    available_cols = [c for c in audio_cols if c in df_audio.columns]
    
    # LEFT MERGE: NLP verisi ana tablomuz, Audio verilerini yanÄ±na Ã§ekiyoruz
    merged_df = pd.merge(df_nlp, df_audio[available_cols], on="merge_key", how="left")

    # Rapor
    missing_mask = merged_df['valence'].isna()
    missing_count = missing_mask.sum()
    
    print("-" * 30)
    print(f"ğŸ“Š Toplam NLP ÅarkÄ±sÄ±: {len(df_nlp)}")
    print(f"âœ… EÅŸleÅŸen ÅarkÄ±: {len(df_nlp) - missing_count}")
    print(f"âš ï¸ Bulunamayan: {missing_count}")
    print("-" * 30)
    
    # --- DEBUG: BulunamayanlarÄ± GÃ¶ster ---
    if missing_count > 0:
        print("\nğŸ” EÅŸleÅŸmeyen Ä°lk 10 Ã–rnek (Hata AyÄ±klama Ä°Ã§in):")
        missing_rows = merged_df[missing_mask].head(10)
        for idx, row in missing_rows.iterrows():
            print(f"   -> {row['track name']} | SanatÃ§Ä±: {row['artists']}")
            print(f"      OluÅŸan Key: {row['merge_key']}")
        print("\n(Not: Bu ÅŸarkÄ±lar Audio CSV dosyasÄ±nda olmayabilir veya isimleri Ã§ok farklÄ± olabilir.)")

    # BulunamayanlarÄ± Ã§Ä±kar (Analiz iÃ§in boÅŸ veri iÅŸe yaramaz)
    merged_df = merged_df.dropna(subset=['valence'])

    if merged_df.empty:
        print("âŒ HATA: HiÃ§bir veri eÅŸleÅŸmedi! Dosya isimlerini veya sÃ¼tunlarÄ± kontrol et.")
        return

    # --- Normalizasyon ve Hesaplama ---
    print("ğŸ§® Hesaplamalar yapÄ±lÄ±yor...")
    features_to_scale = [
        "danceability", "energy", "loudness", "speechiness", 
        "acousticness", "instrumentalness", "liveness", "valence", "tempo"
    ]
    
    scaler = MinMaxScaler()
    merged_df[features_to_scale] = scaler.fit_transform(merged_df[features_to_scale])

    merged_df["emotionality"] = (
        (1 - merged_df["valence"]) * 0.40 +
        merged_df["acousticness"] * 0.20 +
        (1 - merged_df["energy"]) * 0.10 +
        merged_df["instrumentalness"] * 0.10 +
        (1 - merged_df["tempo"]) * 0.10 +
        (1 - merged_df["loudness"]) * 0.10
    )

    # --- Final Format ---
    merged_df = merged_df.reset_index(drop=True)
    merged_df["id"] = merged_df.index + 1
    
    # Final sÃ¼tunlarÄ± seÃ§
    final_cols = ["id", "artists", "track name", "emotionality", "emotion_type", "emotion_score", "culture"]
    
    final_output = merged_df[final_cols]
    final_output.to_csv(OUTPUT_FILENAME, index=False)
    
    print(f"\nâœ… DOSYA HAZIR: {OUTPUT_FILENAME}")
    print(final_output.head())

if __name__ == "__main__":
    create_final_dataset()